{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install safetensors\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from safetensors.torch import load_model\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        This module applies two consecutive convolutional layers to the input.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "        \"\"\"\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the DoubleConv module.\"\"\"\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512, 1024]):\n",
    "        \"\"\"\n",
    "        Basic U-Net model for image to image\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int, optional): Number of input channels.\n",
    "            out_channels (int, optional): Number of output channels.\n",
    "            features (list, optional): List of features for encoding and decoding.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Encoder\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Decoder\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "        \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the U-Net model\"\"\"\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)\n",
    "            skip_connection = skip_connections[i//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.functional.interpolate(x, size=skip_connection.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[i+1](concat_skip)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_image(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_array):\n",
    "    # Convert from channels-first to channels-last\n",
    "    image_array = image_array = image_array[0].numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    plt.imshow(image_array)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(512),\n",
    "        transforms.CenterCrop(512),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Gets the best device to load the model to\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = UNet()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "load_model(model, hf_hub_download(repo_id=\"erickillian/tattoo-removal\", filename=\"tattoo_remover.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://media.gq.com/photos/57b643441890ff58025997be/master/w_1600%2Cc_limit/travis-barker-gq-19.jpg\"\n",
    "image = get_url_image(url)\n",
    "input = image_transforms(image)\n",
    "input = torch.unsqueeze(input, 0)\n",
    "\n",
    "display_image(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward the image through the model\n",
    "with torch.no_grad():\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "\n",
    "display_image(output.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
